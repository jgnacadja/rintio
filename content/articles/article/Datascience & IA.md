---
title:  Datascience & IA
published: true
categories: ["Nos publications"]
date: 2020-07-28
coverImage: /img/articles/f818eb3710_119299_intelligence.png
---


L’exploitation des données internes et externes à l’entreprise est clairement d’actualité. 
Rintio, entreprise du numérique est conscient du vrai potentiel qu’offrent ces données pour l’aide à la prise de décision. 
Pour cela, de nombreuses expressions sont employées pour mentionner la collecte et l’analyse de ces données : Big Data, Data Science ou encore Business Intelligence.


# Big Data

La notion fait référence à la collecte d’un volume important de données puis à l’analyse en temps réel de celles-ci.
Les analyses requises pour traiter le nombre impressionnant de données nécessitent des moyens techniques et informatiques. 
Les logiciels dans la veine d’EthnosData permettent de traiter l’ensemble de ces données dans un temps court et très acceptable.

# Data Science

La Data Science consiste à mettre au point des séries d’algorithmes à partir de règles mathématiques et statistiques (ou de Machine Learning) afin de délivrer des solutions. 
Ces techniques peuvent s’appuyer sur l’analyse d’image, l’analyse de textes (text-mining), l’étude de corrélation entre capteurs, etc.

Le lien entre les deux apparaît alors : afin d’analyser les amas de données, le Big Data repose sur les algorithmes développés par la Data Science. Plus loin avec les chantiers de digitalisation engagés par les entreprises et les institutions, la Data Science voit son champs d’applications profondément s’élargir : rationalisation de la logistique, optimisation des achats, études de corrélation, ajustements des politiques prix, etc. Les projets d’optimisation de la chaîne de valeur sont très nombreux. 
C’est dans ce sens que d’aucuns perçoivent la Data Science comme étant le prochain département contrôle de Gestion appliqué aux données (et non aux activités financières).

Commençons par décrire l’Intelligence Artificielle comme la mise en œuvre d’agents intelligents. 
D’après Peter Norvig et Stuart Russel, un agent intelligent est une entité autonome capable de percevoir son environnement grâce à des capteurs, d’agir sur celui-ci grâce à des actionneurs (autrement dit d’interagir avec son environnement), capable d’apprendre, d’analyser, d’utiliser des connaissances, et de prendre des décisions.

Historiquement, les premières I.A. n’étaient pas réellement « apprenantes ». 
Elles utilisaient au mieux des fonctions heuristiques combinées avec des moteurs de règles. 
Aujourd’hui, l’évolution des technologies ne nous fait plus concevoir une I.A. qui ne soit pas « apprenante ». 
En particulier grâce aux progrès récents des algorithmes d’apprentissage profond (deep learning).

Et justement, le fait de faire « apprendre » à une machine s’appelle littéralement le « machine learning ». 
Celui-ci s’appuie sur des algorithmes (principalement statistiques) pour permettre à une machine « d’apprendre » à partir d’un certain nombre de réponses correctes disponibles connues au départ (échantillon ou base d’apprentissage). 
Sans cette base de données disponible, souvent très volumineuse, l’apprentissage n’est pas possible.

# Le Machine Learning, discipline majeure de l’Intelligence Artificielle

Une première évidence, d’après ces définitions, est que le machine learning est une discipline majeure de l’intelligence artificielle moderne. Or, les algorithmes qui rendent l’apprentissage possible ont principalement été développés grâce à une autre discipline, sensiblement plus ancienne, connue sous le nom de Statistique.

Plus l’algorithme est simple, plus il est proche de la statistique de base ; plus il est complexe, plus il fait appel à des combinaisons de démarches statistiques élémentaires qui constituent donc les briques de base du machine learning moderne (tel que l’explique par exemple très bien l’éminent Data Scientist et mathématicien russe Vladimir Vapnik). On soulignera au passage que plus l’algorithme est complexe, plus celui-ci sera précis, mais plus il nécessitera une base d’apprentissage importante pour pouvoir fonctionner.

Comme une grosse partie du succès de la statistique et du machine learning repose sur une bonne préparation et une bonne transformation des données, on voit apparaitre très vite une discipline qui englobe a minima la data préparation, la statistique et le machine learning, que l’on peut appeler sans prendre de risque la « Data Science ».

La discipline englobante qui permet de développer toutes sortes d’algorithmes pour l’I.A. s’appelle donc couramment la « Data Science », ses praticiens étant des Data Scientists ou des Data Engineers.

Il semble parfaitement évident que la Data Science et l’Intelligence Artificielle ont énormément en commun.

# Mais peut-on englober l’I.A. dans la Data Science ?

Dans l’absolu, la partie collecte et la partie restitution des informations font bien évidemment partie intégrante de la Data Science. En effet, une des difficultés majeures de la Data Science consiste par ailleurs à être en capacité de bien restituer l’information et de bien expliquer la connaissance acquise des algorithmes aux métiers.

Si on considère que le fait de percevoir son environnement grâce à des capteurs fait partie du processus de collecte d’information, et que la partie qui permet à un agent d’agir sur celui-ci directement grâce à des actionneurs fait partie de l’activité de restitution de cette information ou de cette connaissance, il ne nous reste alors plus qu’à examiner la partie « intelligente » de l’I.A. pour savoir si on peut englober cette activité dans la Data Science.

Cette partie « Intelligente » se définit comme nous l’avons vu comme la capacité pour un agent intelligent d’apprendre, d’analyser, d’utiliser des connaissances, et de prendre des décisions. Nous avons nommé cette activité « machine learning », et admis qu’elle était une partie intégrante (et même majeure) de la Data Science.

Cette partie « Intelligente » se définit comme nous l’avons vu comme la capacité pour un agent intelligent d’apprendre, d’analyser, d’utiliser des connaissances, et de prendre des décisions. Nous avons nommé cette activité « machine learning », et admis qu’elle était une partie intégrante (et même majeure) de la Data Science.

# L’Intelligence artificielle est la discipline la plus complexe de la Data Science

Ceci nous amène à légitimement définir la Data Science comme la réunion de quatre disciplines hybrides :

   la préparation des données,
   la statistique,
   le machine learning,
   et l’Intelligence Artificielle.


On constate donc que ces termes ne sont pas du tout interchangeables. Les praticiens qui pratiquent une ou plusieurs de ces quatre disciplines sont tous des Data Scientists ou des Data Enginners.

Ces quatre disciplines sont, pour rappel, imbriquées et interdépendantes puisque sans machine learning, de nos jours, on ne peut pas faire d’Intelligence Artificielle, sans statistique on ne peut pas faire de machine learning et sans transformation de la donnée, on en peut pas réussir ses modèles statistiques.

Parmi toutes les disciplines de la Data Science, l’I.A. est la plus complexe d’entre elles à mettre en œuvre, car elle fait nécessairement appel aux trois autres, depuis la dataprep, jusqu’au machine learning.

On ne peut cependant pas, sauf (gros) abus de langage, remplacer le terme Data Science par I.A., qui est en seulement une des utilisations, voire probablement l’aboutissement d’un point de vue savoir-faire.

# Les enjeux et objectifs de la data science

L’objectif du data scientist est d’explorer, de trier et d’analyser des mégadonnées de sources diverses afin d’en tirer parti et d’arriver à des conclusions pour optimiser les processus métiers ou pour l’aide à la prise de décision. 
On retrouvera par exemple la maintenance des machines ou (maintenance prédictive), dans les domaines du marketing et de la vente avec de la prédiction des ventes en fonction de la météo par exemple. 
Les cas d’usages sont quasiment infinis…

Les piliers sur lesquels le data scientist s’appuie le plus souvent sont le data mining (exploration de la donnée), les statistiques, le machine learning, les algorithmes de recherche (random forest, arbre de décision, régression, réseau de neurone…), la visualisation des données (Dataviz) avec des outils tel que Matlo, Qlik… La data science est donc en train de révolutionner le traitement des données des entreprises ou données publiques qui jusque-là étaient difficilement exploitables avec les technologies classiques (dites structurées). 
La concomitance entre l’accroissement fulgurant des bases de données, de l’émergence de nouvelles technologies autour du machine learning, de l’intelligence artificielle et du Big Data permettent désormais de réaliser de l’analyse de donnée semi-structurée.

On parle beaucoup de Data science lorsqu’on évoque le Big Data, mais elle ne se limite pas uniquement aux ensembles massifs de données. Chez Saagie par exemple, nous pensons qu’il est préférable de parler de Smart Data : il est possible de tirer parti de la donnée quelle que soit sa taille.

On retrouvera une forte appétence pour la data science dans les domaines tels que :

   Industrie :
        Maintenance prédictive
   Les banques et assurances avec :
        Automatisation des processus
        La connaissance client
        La réduction du taux d’attrition
    Santé :
         Epidémiologie
        Toxicologie
        Recherches
    Retail :
        Prévision des ventes
        Customer 360
        marketing prédictif
        Environnements
        Modélisation des phénomènes climatiques
        Projection de l’impact
    Transport & villes :
        Villes intelligentes (smart cities)
        Optimisation des transports en fonction des flux voyageurs


Les cas d’usage ne manquent pas ! La principale difficulté de la data science est son aspect très largement pluridisciplinaire à la croisée entre les sciences classiques, les logicielles et langages de programmation, la sécurité des données…

